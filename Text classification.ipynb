{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"hi, how are you!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi,', 'how', 'are', 'you!']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', ',', 'how', 'are', 'you', '!']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1\n",
      "  (0, 9)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 22)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 8)\t1\n",
      "  (1, 10)\t1\n",
      "  (1, 13)\t1\n",
      "  (1, 17)\t1\n",
      "  (1, 19)\t1\n",
      "  (1, 22)\t2\n",
      "  (2, 0)\t1\n",
      "  (2, 5)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 14)\t1\n",
      "  (2, 22)\t1\n",
      "  (3, 12)\t1\n",
      "  (3, 15)\t1\n",
      "  (3, 16)\t1\n",
      "  (3, 18)\t1\n",
      "  (3, 20)\t1\n",
      "  (4, 21)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = [\n",
    "    \"hello, how are you?\",\n",
    "\"im getting bored at home. And you? What do you think?\",\n",
    "\"did you know about counts\",\n",
    "\"let's see if this works!\",\n",
    "\"YES!!!!\"\n",
    "]\n",
    "\n",
    "ctv = CountVectorizer()\n",
    "\n",
    "ctv.fit(corpus)\n",
    "\n",
    "corpus_transformed = ctv.transform(corpus)\n",
    "print(corpus_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hello': 9, 'how': 11, 'are': 2, 'you': 22, 'im': 13, 'getting': 8, 'bored': 4, 'at': 3, 'home': 10, 'and': 1, 'what': 19, 'do': 7, 'think': 17, 'did': 6, 'know': 14, 'about': 0, 'counts': 5, 'let': 15, 'see': 16, 'if': 12, 'this': 18, 'works': 20, 'yes': 21}\n"
     ]
    }
   ],
   "source": [
    "print(ctv.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hello': 14, ',': 2, 'how': 16, 'are': 7, 'you': 27, '?': 4, 'im': 18, 'getting': 13, 'bored': 9, 'at': 8, 'home': 15, '.': 3, 'and': 6, 'what': 24, 'do': 12, 'think': 22, 'did': 11, 'know': 19, 'about': 5, 'counts': 10, 'let': 20, \"'s\": 1, 'see': 21, 'if': 17, 'this': 23, 'works': 25, '!': 0, 'yes': 26}\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "ctv = CountVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
    "ctv.fit(corpus) #corpus is a list of texts\n",
    "corpus_transformed = ctv.transform(corpus)\n",
    "print(ctv.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count vectorizer is a bag of words model\n",
    "# tfidfvectorizer is TF-IDF \n",
    "# Both comes under sklearn.feature_extractor.text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " imdb.csv   log_res.py  'Text classification.ipynb'\r\n"
     ]
    }
   ],
   "source": [
    "ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('imdb.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I always wrote this series off as being a comp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This movie was so poorly written and directed ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The most interesting thing about Miryang (Secr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>when i first read about \"berlin am meer\" i did...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  label\n",
       "0           0  I always wrote this series off as being a comp...      0\n",
       "1           1  1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...      0\n",
       "2           2  This movie was so poorly written and directed ...      0\n",
       "3           3  The most interesting thing about Miryang (Secr...      1\n",
       "4           4  when i first read about \"berlin am meer\" i did...      0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I always wrote this series off as being a comp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>This movie was so poorly written and directed ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The most interesting thing about Miryang (Secr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>when i first read about \"berlin am meer\" i did...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>4995</td>\n",
       "      <td>Man, I loved this movie! This really takes me ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>4996</td>\n",
       "      <td>Recovery is an incredibly moving piece of work...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>4997</td>\n",
       "      <td>You can take the crook out of the joint, but i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>4998</td>\n",
       "      <td>FUTZ is the only show preserved from the exper...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>4999</td>\n",
       "      <td>\"The Mother\" tells of a recently widowed mid-6...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                               text  label\n",
       "0               0  I always wrote this series off as being a comp...      0\n",
       "1               1  1st watched 12/7/2002 - 3 out of 10(Dir-Steve ...      0\n",
       "2               2  This movie was so poorly written and directed ...      0\n",
       "3               3  The most interesting thing about Miryang (Secr...      1\n",
       "4               4  when i first read about \"berlin am meer\" i did...      0\n",
       "...           ...                                                ...    ...\n",
       "49995        4995  Man, I loved this movie! This really takes me ...      1\n",
       "49996        4996  Recovery is an incredibly moving piece of work...      1\n",
       "49997        4997  You can take the crook out of the joint, but i...      1\n",
       "49998        4998  FUTZ is the only show preserved from the exper...      1\n",
       "49999        4999  \"The Mother\" tells of a recently widowed mid-6...      1\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000.000000</td>\n",
       "      <td>50000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>16499.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12493.456486</td>\n",
       "      <td>0.500005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4166.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14999.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>27499.250000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>39999.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0         label\n",
       "count  50000.000000  50000.000000\n",
       "mean   16499.500000      0.500000\n",
       "std    12493.456486      0.500005\n",
       "min        0.000000      0.000000\n",
       "25%     4166.000000      0.000000\n",
       "50%    14999.500000      0.500000\n",
       "75%    27499.250000      1.000000\n",
       "max    39999.000000      1.000000"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "tfv = TfidfVectorizer(tokenizer=word_tokenize, token_pattern=None)\n",
    "tfv.fit(corpus)\n",
    "transformed_corpus = tfv.transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 27)\t0.2965698850220162\n",
      "  (0, 16)\t0.4428321995085722\n",
      "  (0, 14)\t0.4428321995085722\n",
      "  (0, 7)\t0.4428321995085722\n",
      "  (0, 4)\t0.35727423026525224\n",
      "  (0, 2)\t0.4428321995085722\n",
      "  (1, 27)\t0.35299699146792735\n",
      "  (1, 24)\t0.2635440111190765\n",
      "  (1, 22)\t0.2635440111190765\n",
      "  (1, 18)\t0.2635440111190765\n",
      "  (1, 15)\t0.2635440111190765\n",
      "  (1, 13)\t0.2635440111190765\n",
      "  (1, 12)\t0.2635440111190765\n",
      "  (1, 9)\t0.2635440111190765\n",
      "  (1, 8)\t0.2635440111190765\n",
      "  (1, 6)\t0.2635440111190765\n",
      "  (1, 4)\t0.42525129752567803\n",
      "  (1, 3)\t0.2635440111190765\n",
      "  (2, 27)\t0.31752680284846835\n",
      "  (2, 19)\t0.4741246485558491\n",
      "  (2, 11)\t0.4741246485558491\n",
      "  (2, 10)\t0.4741246485558491\n",
      "  (2, 5)\t0.4741246485558491\n",
      "  (3, 25)\t0.38775666010579296\n",
      "  (3, 23)\t0.38775666010579296\n",
      "  (3, 21)\t0.38775666010579296\n",
      "  (3, 20)\t0.38775666010579296\n",
      "  (3, 17)\t0.38775666010579296\n",
      "  (3, 1)\t0.38775666010579296\n",
      "  (3, 0)\t0.3128396318588854\n",
      "  (4, 26)\t0.2959842226518677\n",
      "  (4, 0)\t0.9551928286692534\n"
     ]
    }
   ],
   "source": [
    "print(transformed_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N-grams are combinations of words in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('hi', ',', 'how'), (',', 'how', 'are'), ('how', 'are', 'you'), ('are', 'you', '?')]\n"
     ]
    }
   ],
   "source": [
    "from nltk import ngrams\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "N =3\n",
    "sentence = \"hi, how are you?\"\n",
    "tokenized_sentence = word_tokenize(sentence)\n",
    "\n",
    "n_grams = list(ngrams(tokenized_sentence, N))\n",
    "print(n_grams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## stemming gives the smallest word possible and lemmatization gives the appropriate word; gives lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word = fishing\n",
      "lemmatized_word = fishing\n",
      "stemmed_word = fish\n",
      "\n",
      "word = fish\n",
      "lemmatized_word = fish\n",
      "stemmed_word = fish\n",
      "\n",
      "word = fished\n",
      "lemmatized_word = fished\n",
      "stemmed_word = fish\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "words = [\"fishing\", \"fish\", \"fished\"]\n",
    "\n",
    "for word in words:\n",
    "    print(f\"word = {word}\")\n",
    "    print(f\"lemmatized_word = {lemmatizer.lemmatize(word)}\")\n",
    "    print(f\"stemmed_word = {stemmer.stem(word)}\")\n",
    "    print(\"\")\n",
    "          \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Extraction\n",
    "\n",
    "## non-negative matrix factorization(NMF) or latent semantic analysis(LSA), which is popularly known as Singular value decomposition(SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
